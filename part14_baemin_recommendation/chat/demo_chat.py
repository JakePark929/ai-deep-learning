import json
import os
import requests
import sys
from dotenv import load_dotenv
sys.path.insert(0, "..")

import gradio as gr
from openai import OpenAI

from utils import call_openai

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

SYSTEM_PROMPT = f"""ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ë©”ë‰´ëšë”±AI'ì´ë©° ë‹¹ì‹ ì˜ ì—­í• ì€ ë°°ë‹¬ì˜ë¯¼ì¡±ì´ë¼ëŠ” ìŒì‹ ì£¼ë¬¸ ëª¨ë°”ì¼ ì–´í”Œì—ì„œ ë¦¬ë·° í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë©”ë‰´ë¥¼ ì¶”ì²œí•´ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì‹¤ì œ ë°°ë‹¬ì˜ë¯¼ì¡± ì–´í”Œ ë‚´ ì£¼ë¬¸ì´ ê°€ëŠ¥í•œ ë©”ë‰´ ë° ìŒì‹ì ì„ ì¶”ì²œí•´ì¤˜ì•¼ í•˜ë©° ë‹¨ìˆœí•œ ë©”ë‰´ëª…ì„ ì¶”ì²œí•´ì¤„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ex. í•´ì¥êµ­, íŒŒìŠ¤íƒ€)
ì¶”ì²œ ê°€ëŠ¥í•œ ë©”ë‰´ëŠ” recommend í•¨ìˆ˜ë¥¼ í†µí•´ ê²°ê³¼ë¥¼ ë°›ì•„ ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©”ë‰´ ì¶”ì²œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ API ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìµœìƒì˜ ì¶”ì²œ ê²°ê³¼ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
"""

MESSAGES = [
    {
        'role': 'system',
        'content': SYSTEM_PROMPT
    }
]

TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "recommend",
            "description": "ì‚¬ìš©ì ë°œí™” ê¸°ë°˜ìœ¼ë¡œ ë©”ë‰´ ì¶”ì²œ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì˜¤ë¡œì§€ ì´ í•¨ìˆ˜ ê²°ê³¼ë¡œë§Œ ë©”ë‰´ ì¶”ì²œë˜ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ í•´ì¥ ë˜ëŠ” ë‹¤ì´ì–´íŠ¸ 2ê°œ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ë©”ë‰´ ì¶”ì²œë§Œ ê°€ëŠ¥í•˜ë©°, ì‚¬ìš©ì ë°œí™”ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ë°˜í™˜ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query_text": {
                        "type": "string",
                        "description": "ì‚¬ìš©ì ë°œí™” í…ìŠ¤íŠ¸ ì›ë¬¸",
                    },
                },
                "required": ["query_text"],
                "additionalProperties": False,
            },
        }
    }
]

def recommend(query_text):
    url = "http://localhost:8000/recommend"
    response = requests.post(url, json={"query_text": query_text})
    return response.json()

def call_openai(prompt, temperature=0.0, model='gpt-4o-2024-08-06'):
    client = OpenAI(api_key=OPENAI_API_KEY)

    MESSAGES.append(
        {
            'role': 'user',
            'content': prompt
        }
    )

    completion = client.chat.completions.create(
        model=model,
        messages=MESSAGES,
        tools=TOOLS,
        tool_choice="auto"
    )

    if hasattr(completion.choices[0].message, "tool_calls") and completion.choices[0].message.tool_calls:
        tool_calls = completion.choices[0].message.tool_calls  # ğŸ”¥ ìˆ˜ì •ëœ ë¶€ë¶„
        tool_name = tool_calls[0].function.name
        tool_args = tool_calls[0].function.arguments
        tool_id = tool_calls[0].id
        MESSAGES.append(
            {
                "role": "assistant",
                "content": None,
                "tool_calls": [
                    {
                        "id": tool_id,
                        "type": "function",
                        "function": {
                            "name": tool_name,
                            "arguments": tool_args
                        }
                    }
                ]
            }
        )

        tool_result = recommend(**json.loads(tool_args))
        MESSAGES.append(
            {
                "role": "tool",
                "content": json.dumps(tool_result, ensure_ascii=False),
                "tool_call_id": tool_id
            }
        )

        completion = client.chat.completions.create(
            model=model,
            messages=MESSAGES,
            tools=TOOLS
        )

    MESSAGES.append(
        {
            "role": "assistant",
            "content": completion.choices[0].message.content
        }
    )

    return completion.choices[0].message.content

def fn(message, history):
    output = call_openai(message)
    return output

def run_demo():
    demo = gr.ChatInterface(
        title='ë©”ë‰´ëšë”± AI â™¾',
        fn=fn,
        examples=["ìˆ™ì·¨ì— ì¢‹ì€ ë©”ë‰´ ì¢€ ì¶”ì²œí•´ì¤„ë ˆ...?"]
    )
    demo.launch(share=True)

if __name__ == '__main__':
    run_demo()