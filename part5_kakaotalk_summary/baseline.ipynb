{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 모델 개발 및 평가 지표 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용 기반 후보 모델 선정\n",
    "\n",
    "- Claude 3 Haiku\n",
    "- Gemini 1.5 Flash\n",
    "- ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_eval_data()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gemini-1.5-flash-001'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(len(get_eval_data()))):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=PROMPT_BASELINE,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    mean = sum(scores[model]) / len(scores[model])\n",
    "    variance = sum((x - mean) ** 2 for x in scores[model]) / (len(scores[model]) - 1)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    print(f'{model}: {mean} / {round(std_dev, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(model, max(scores[model]), min(scores[model]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kakao",
   "language": "python",
   "name": "kakao"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
