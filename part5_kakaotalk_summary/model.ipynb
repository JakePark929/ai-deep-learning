{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 고도화\n",
    "- Few-Shot Prompting\n",
    "- Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize, get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Get Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_train = get_train_data()[18]\n",
    "print(conv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sample = \"\"\"최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"당신은 요약 전문가입니다. 사용자 대화들이 주어졌을 때 요약하는 것이 당신의 목표입니다. 다음은 사용자 대화와 요약 예시입니다.\n",
    "예시 대화:\n",
    "{conv_train}\n",
    "예시 요약 결과:\n",
    "{summary_sample}\n",
    "    \n",
    "아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    # 'gemini-1.5-flash-001',\n",
    "    # 'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(5)):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=prompt,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(5)):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=prompt,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain-of-thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sample = \"\"\"최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"당신은 요약 전문가입니다. 사용자 대화들이 주어졌을 때 요약하는 것이 당신의 목표입니다. 대화를 요약할 때는 다음 단계를 따라주세요:\n",
    "\n",
    "1. 대화 참여자 파악: 대화에 참여하는 사람들의 수와 관계를 파악합니다.\n",
    "2. 주제 식별: 대화의 주요 주제와 부차적인 주제들을 식별합니다.\n",
    "3. 핵심 내용 추출: 각 주제에 대한 중요한 정보나 의견을 추출합니다.\n",
    "4. 감정과 태도 분석: 대화 참여자들의 감정이나 태도를 파악합니다.\n",
    "5. 맥락 이해: 대화의 전반적인 맥락과 배경을 이해합니다.\n",
    "6. 특이사항 기록: 대화 중 특별히 눈에 띄는 점이나 중요한 사건을 기록합니다.\n",
    "7. 요약문 작성: 위의 단계에서 얻은 정보를 바탕으로 간결하고 명확한 요약문을 작성합니다.\n",
    "각 단계를 수행한 후, 최종적으로 전체 대화를 200자 내외로 요약해주세요.\n",
    "\n",
    "예시 대화:\n",
    "{conv_train}\n",
    "예시 요약 결과:\n",
    "{summary_sample}\n",
    "    \n",
    "아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(5)):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=prompt,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"당신은 요약 전문가입니다. 사용자 대화들이 주어졌을 때 요약하는 것이 당신의 목표입니다. 대화를 요약할 때는 다음 단계를 따라주세요:\n",
    "\n",
    "1. 대화 참여자 파악: 대화에 참여하는 사람들의 수와 관계를 파악합니다.\n",
    "2. 주제 식별: 대화의 주요 주제와 부차적인 주제들을 식별합니다.\n",
    "3. 핵심 내용 추출: 각 주제에 대한 중요한 정보나 의견을 추출합니다.\n",
    "4. 감정과 태도 분석: 대화 참여자들의 감정이나 태도를 파악합니다.\n",
    "5. 맥락 이해: 대화의 전반적인 맥락과 배경을 이해합니다.\n",
    "6. 특이사항 기록: 대화 중 특별히 눈에 띄는 점이나 중요한 사건을 기록합니다.\n",
    "7. 요약문 작성: 위의 단계에서 얻은 정보를 바탕으로 간결하고 명확한 요약문을 작성합니다.\n",
    "각 단계를 수행한 후, 최종적으로 전체 대화를 200자 내외로 요약해주세요.\n",
    "\n",
    "아래는 예시 대화와 예시 요약 과정 및 결과 입니다.\n",
    "\n",
    "예시 대화:\n",
    "{conv_train}\n",
    "\n",
    "예시 요약 과정\n",
    "1. \"우리 대학교 졸업 여행 간 거 기억나?\"라는 언급과 전반적으로 친밀한 대화 톤을 사용하고 있는 것을 보았을 떄 두 사용자는 오랜 친구 사이로 보입니다.\n",
    "대화의 시작 부분에서 \"코로나가 좀 잠잠해지면 해외여행 중에 가고 싶은 곳 있어?\"라고 묻고 있는 것을 보았을 때 코로나 이후 가고 싶은 해외 여행지에 대해 논의하고 있습니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "\n",
    "2. 대화 중 호주, 일본, 하와이, 괌, 베트남 다낭, 스위스, 유럽들이 언급하고 있습니다.\n",
    "남편의 첫 직장 워크샵, 대학교 졸업 여행, 호주 워킹홀리데이 등의 경험을 이야기하면서 과거 여행 경험을 공유하며 추억을 회상하고 있습니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "\n",
    "3. 소매치기, 여권 분실, 인도에서의 여성 여행자 위험 등을 언급하며 해외 여행의 위험성에 대해 우려를 표현하고 있습니다.\n",
    "\"해외 여행 가면 가이드 안 끼고 가면 영어 실력 엄청 좋은 사람이랑 가는 거 아닐 땐 소통 문제도 좀 곤란할 때가 있는 거 같아\"라는 언급과 \"왜 영어 공부를 열심히 안 했을까... 후회\"라는 표현이 있는 것을 보았을 때 언어 장벽의 어려움을 인식하고 영어 실력 향상에 대한 욕구를 표현합니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\n",
    "\n",
    "예시 요약 결과\n",
    "최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\n",
    "    \n",
    "아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(5)):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=prompt,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    # 'gemini-1.5-flash-001',\n",
    "    # 'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(len(get_eval_data()))):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=prompt,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for model in scores:\n",
    "    mean = sum(scores[model]) / len(scores[model])\n",
    "    variance = sum((x - mean) ** 2 for x in scores[model]) / (len(scores[model]) - 1)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    print(f'{model}: {mean} / {round(std_dev, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_eval_data()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\"\n",
    "\n",
    "summary = summarize(\n",
    "    conversation=get_eval_data()[10],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[10],\n",
    "    prompt=prompt,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kakao",
   "language": "python",
   "name": "kakao"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
