import os

from openai import OpenAI
from dotenv import load_dotenv
# from langchain_huggingface import HuggingFaceEmbeddings # type: ignore
from langchain_openai import OpenAIEmbeddings

import streamlit as st

from faiss_manager import FAISSIndexManager

### DB ê²½ë¡œ ì„¤ì • ###
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_PATH = os.getenv("INDEX_PATH")
index_path = INDEX_PATH

### ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ###
embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
# embedding = HuggingFaceEmbeddings(model_name="distiluse-base-multilingual-cased-v1")

### FAISS ì¸ë±ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ###
faiss_manager = FAISSIndexManager(index_path, embedding)

### ëª¨ë¸ ì„ ì–¸ ###
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)
model="gpt-3.5-turbo-0125"

### OpenAI API ìƒì„± ###
def chatgpt_generate(query):
    message = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì—°êµ¬ì— ê´€í•œ ì§ˆë¬¸ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì§ˆë¬¸ì— ì²¨ë¶€ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.
            ë‹µë³€ ê²°ê³¼ëŠ” ë‹¤ìŒ ì¡°ê±´ë“¤ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
            1. ëª¨ë“  ë¬¸ì¥ì€ í•­ìƒ ì¡´ëŒ“ë§ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
            """
        },
        {
            "role": "user",
            "content": query
        },
    ]
    response = client.chat.completions.create(model=model, messages=message)
    answer = response.choices[0].message.content

    return answer

### í”„ë¡¬í”„íŠ¸ ìƒì„± ###
def prompt_and_generate(query):
    docs = [doc for doc in faiss_manager.search(query)]
    prompt = f"""ì•„ë˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ëœ ì§ˆë¬¸ì— ì²¨ë¶€ëœ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ì‹œì˜¤. ë¬¸ì„œì— ìˆëŠ” ì¶œì²˜ë„ ëª…ì‹œí•©ë‹ˆë‹¤.
        ì§ˆë¬¸: {query}\n"""

    for i in range(len(docs)):
        prompt += f"ë¬¸ì„œ{i + 1}\n"
        prompt += f"ë‚´ìš©: {docs[i].page_content}\n"  # page_contentë¡œ ë¬¸ì„œ ë‚´ìš© ì ‘ê·¼
        prompt += f"ì¶œì²˜: {docs[i].metadata['source']}, í˜ì´ì§€: {docs[i].metadata['page']}\n"  # metadataì—ì„œ ì¶œì²˜ì™€ í˜ì´ì§€ ì •ë³´ ì ‘ê·¼
        prompt += "\n"  # ë¬¸ì„œ ê°„ êµ¬ë¶„ì„ ìœ„í•œ ì¤„ë°”ê¿ˆ

    prompt += "ë‹µë³€: "
    # print(f"prompt: {prompt}\n")
    answer = chatgpt_generate(prompt)

    return answer

### Client êµ¬í˜„ ###
st.title("ğŸ§‘â€ğŸ”¬Wisebot: AI Research Assistant")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.markdown(message['content'])

if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    response = f"bot: {prompt_and_generate(prompt.strip())}"

    with st.chat_message("assistant"):
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})